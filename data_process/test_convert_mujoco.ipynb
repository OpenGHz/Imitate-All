{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import convert_all as crd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果左右臂数据采集反了，交换前7个和后7个数据\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def print_hdf5_structure(hdf5_file_path):\n",
    "    with h5py.File(hdf5_file_path, 'r') as f:\n",
    "        def print_attrs(name, obj):\n",
    "            print(name)\n",
    "        f.visititems(print_attrs)\n",
    "\n",
    "def swap_data(hdf5_file_path):\n",
    "    with h5py.File(hdf5_file_path, 'r+') as f:\n",
    "        # 读取 action 和 qpos 数据\n",
    "        action_data = f['/action'][:]\n",
    "        qpos_data = f['observations/qpos'][:]\n",
    "        \n",
    "        # 交换 action 数据的前 7 个和后 7 个数据\n",
    "        action_data[:, :7], action_data[:, -7:] = action_data[:, -7:], action_data[:, :7].copy()\n",
    "        \n",
    "        # 交换 qpos 数据的前 7 个和后 7 个数据\n",
    "        qpos_data[:, :7], qpos_data[:, -7:] = qpos_data[:, -7:], qpos_data[:, :7].copy()\n",
    "        \n",
    "        # 将交换后的数据写回文件\n",
    "        f['/action'][:] = action_data\n",
    "        f['observations/qpos'][:] = qpos_data\n",
    "# 文件路径模板\n",
    "# file_template = '/home/qiuzhi/IMITATION_LEARNING/Imitate-All/demonstrations/hdf5/dual_put_two_cups_to_bowl/episode_{:02d}.hdf5'\n",
    "\n",
    "# # 遍历指定范围内的所有文件\n",
    "# for episode in range(30, 50):\n",
    "#     hdf5_file_path = file_template.format(episode)\n",
    "#     if os.path.exists(hdf5_file_path):\n",
    "#         print(f\"Processing {hdf5_file_path}\")\n",
    "#         swap_data(hdf5_file_path)\n",
    "#     else:\n",
    "#         print(f\"File {hdf5_file_path} does not exist\")\n",
    "# print_hdf5_structure(hdf5_file_path)\n",
    "hdf5_file_path = '/home/qiuzhi/IMITATION_LEARNING/Imitate-All/demonstrations/hdf5/dual_put_two_cups_to_bowl/episode_40.hdf5'\n",
    "swap_data(hdf5_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Converting:   0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m raw_root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../demonstrations/raw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m raw_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_root_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mcrd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_to_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecords.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_file_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflatten_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_converter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/obs/jq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/observations/qpos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/act\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/action\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IMITATION_LEARNING/Imitate-All/data_process/convert_all.py:336\u001b[0m, in \u001b[0;36mraw_to_dict\u001b[0;34m(raw_dir, state_file_names, video_file_names, flatten_mode, name_converter, pre_process, concatenater, key_filter)\u001b[0m\n\u001b[1;32m    332\u001b[0m         data_flat\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;66;03m# if raw_data.pop(key, None) is None:\u001b[39;00m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;66;03m#     print(f\"Key {key} is not found in {state_file}.\")\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# flatten the sub list\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m lenths \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_sublist_in_flat_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m lenths\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# remove not used keys\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;66;03m# print(f\"Remove not used key: {key}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/IMITATION_LEARNING/Imitate-All/data_process/convert_all.py:62\u001b[0m, in \u001b[0;36mflatten_sublist_in_flat_dict\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     60\u001b[0m trajs_lenth \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, traj \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 62\u001b[0m     traj_lenth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m traj_lenth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     64\u001b[0m         point \u001b[38;5;241m=\u001b[39m traj[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# get all low_dim data\n",
    "task_name = \"example_task\"\n",
    "raw_root_dir = \"../demonstrations/raw\"\n",
    "raw_dir = f\"{raw_root_dir}/{task_name}\"\n",
    "data = crd.raw_to_dict(\n",
    "    raw_dir,\n",
    "    [\"records.json\"],\n",
    "    video_file_names=None,\n",
    "    flatten_mode=\"hdf5\",\n",
    "    name_converter={\n",
    "        \"/obs/jq\": \"/observations/qpos\",\n",
    "        \"/act\": \"/action\",\n",
    "    },\n",
    "    pre_process=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(list(data.keys())))\n",
    "print(data.keys())\n",
    "print(data['000'].keys())\n",
    "print(data['000']['/observations/qpos'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "# merge high_dim data and save\n",
    "raw_dir\n",
    "video_names = [\"video.mp4\"]\n",
    "target_root_dir = \"../data/hdf5\"\n",
    "target_dir = f\"{target_root_dir}/{task_name}\"\n",
    "low_dim_data = data\n",
    "name_converter = {\"video\": \"/observations/images/0\"}\n",
    "target_namer = lambda i: f\"episode_{i}.hdf5\"\n",
    "\n",
    "compresser = crd.Compresser(\"jpg\", [int(cv2.IMWRITE_JPEG_QUALITY), 50], True)\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# get max episode length\n",
    "episode_lens = []\n",
    "for low_d in low_dim_data.values():\n",
    "    episode_lens.append(len(list(low_d.values())[0]))\n",
    "\n",
    "max_pad_lenth = max(episode_lens)\n",
    "\n",
    "# save all data\n",
    "episode_names = list(low_dim_data.keys())\n",
    "print(f\"Episode lengths: {episode_lens}\")\n",
    "print(f\"Max episode length: {max_pad_lenth}\")\n",
    "print(f\"All episodes: {episode_names}\")\n",
    "print(f\"episode number: {len(episode_names)}\")\n",
    "\n",
    "def save_one(index, ep_name):\n",
    "    crd.merge_video_and_save(\n",
    "        low_dim_data[ep_name],\n",
    "        f\"{raw_dir}/{ep_name}\",\n",
    "        video_names,\n",
    "        crd.save_dict_to_hdf5,\n",
    "        name_converter,\n",
    "        compresser,\n",
    "        f\"{target_dir}/\" + target_namer(index),\n",
    "        max_pad_lenth,\n",
    "    )\n",
    "    data.pop(ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "futures = []\n",
    "with ThreadPoolExecutor(max_workers=25) as executor:\n",
    "    for index, ep_name in enumerate(episode_names):\n",
    "        # silent execution, no print\n",
    "        futures.append(executor.submit(save_one, index, ep_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_one(0, episode_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check hdf5 data\n",
    "import convert_all as crd\n",
    "task_name = \"mujoco_stack_cups\"\n",
    "target_root_dir = \"../data/hdf5\"\n",
    "target_dir = f\"{target_root_dir}/{task_name}\"\n",
    "data = crd.hdf5_to_dict(f\"{target_dir}/episode_0.hdf5\")\n",
    "print(data.keys())\n",
    "data_flat = crd.flatten_dict(data, prefix=\"/\")\n",
    "print(data_flat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_flat['/compressed_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show actions\n",
    "start = 120\n",
    "end = start + 3\n",
    "\n",
    "action = data_flat[\"/action\"][start:end]\n",
    "obs = data_flat[\"/observations/qpos\"][start+1:end+1]\n",
    "print(action)\n",
    "print(obs)\n",
    "print((obs - action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action[1])\n",
    "print(obs[1])\n",
    "print((obs[1] - action[1]) * 180 / 3.1415926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = data_flat[\"/observations/images/0\"][0]\n",
    "print(image.shape)\n",
    "compresser = crd.Compresser(\"jpg\", [int(cv2.IMWRITE_JPEG_QUALITY), 50], True)\n",
    "image_dc = compresser.decompress(image)\n",
    "print(image_dc.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_dc[:, :, ::-1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imitall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
